{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "( 1.1 ) Word Classification with Machine Learing\n",
    "\n",
    "In this case I classified given Words in different Languages as English and Turkish.\n",
    "The main aim is to predict the Language of a given Word with a Machine Learning algorithm where I used Support Vector Machines,  Naive Bayes and Logistic regression to compare each Algorithm and find the best solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "# I used the Pandas library to read the csv files, to creade the dataframes\n",
    "import pandas as pd\n",
    "# I used the Numpy library to create Numpy arrays for the labels, append the labels to the datas and concatenate two dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading csv files\n",
    "data_eng = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Case\\English.csv\")\n",
    "data_tr = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Case\\Turkish.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the length of each dataset\n",
    "len_en = len(data_eng)\n",
    "len_tr = len(data_tr)\n",
    "\n",
    "# Creating arrays for labels to each category ( English = 0 , Turkish = 1)\n",
    "class_en = np.zeros((len_en,1), dtype=np.int64)\n",
    "class_tr = np.ones((len_tr,1), dtype=np.int64)\n",
    "\n",
    "# Adding the labels as 2. Column to each dataset\n",
    "data_eng = np.append(data_eng, class_en, axis=1)\n",
    "data_tr = np.append(data_tr, class_tr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinating the datasets\n",
    "data = np.concatenate((data_eng, data_tr), axis=0)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Fixing the column names of the dataframe\n",
    "data = data.rename({0: \"word\", 1: \"language\"}, axis='columns')\n",
    "\n",
    "#Cheking if there is any NaN value\n",
    "data.isna().sum() #there is only 1 NaN value\n",
    "\n",
    "# Dropping NaN values\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>flying</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>fillet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>fiance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>fanons</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23896</td>\n",
       "      <td>kalic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23897</td>\n",
       "      <td>korvet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23898</td>\n",
       "      <td>kasaci</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23899</td>\n",
       "      <td>kocma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23900</td>\n",
       "      <td>kumsal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23900 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word language\n",
       "0      flying        0\n",
       "1      fillet        0\n",
       "2      fiance        0\n",
       "3      failed        0\n",
       "4      fanons        0\n",
       "...       ...      ...\n",
       "23896   kalic        1\n",
       "23897  korvet        1\n",
       "23898  kasaci        1\n",
       "23899   kocma        1\n",
       "23900  kumsal        1\n",
       "\n",
       "[23900 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset after the data Preparation ( We have both English and Turkish word in one Column and labeled them as 0 and 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data and Labels\n",
    "X = data['word']\n",
    "y = data['language']\n",
    "#convering type of y to integer\n",
    "y=y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data randomly as train and test\n",
    "# I used the Sklearn library to use the train test split function, to transform the words to vectors,\n",
    "#    Train the data with the naive bayes algorithm and to get the accuracy score\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "X, y, test_size = 0.20, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing words for the algorithm!!\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  0.903347280334728\n"
     ]
    }
   ],
   "source": [
    "# Training model ( Support Vector Machines (Polynomial) )\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "SVM = svm.SVC(C=1.0, kernel='poly', degree=3, gamma='auto')\n",
    "SVM.fit(train_vectors,y_train)\n",
    "\n",
    "# Calculating Accuracy\n",
    "predictions_SVM = SVM.predict(test_vectors)\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  0.8989539748953975\n"
     ]
    }
   ],
   "source": [
    "# Training model ( Support Vector Machines (Linear) )\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(train_vectors,y_train)\n",
    "\n",
    "# Calculating Accuracy\n",
    "predictions_SVM = SVM.predict(test_vectors)\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy Score ->  0.903347280334728\n"
     ]
    }
   ],
   "source": [
    "# Training model ( Multinomial Naive Bayes )\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(train_vectors, y_train)\n",
    "\n",
    "# Calculating Accuracy\n",
    "from  sklearn.metrics  import accuracy_score\n",
    "predicted = clf.predict(test_vectors)\n",
    "print(\"Multinomial Naive Bayes Accuracy Score -> \",accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Accuracy Score ->  0.903347280334728\n"
     ]
    }
   ],
   "source": [
    "# Training model ( Bernoulli Naive Bayes )\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(train_vectors, y_train)\n",
    "\n",
    "# Calculating Accuracy\n",
    "from  sklearn.metrics  import accuracy_score\n",
    "predicted = clf.predict(test_vectors)\n",
    "print(\"Bernoulli Naive Bayes Accuracy Score -> \",accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score ->  0.9072698744769875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Training model ( Logistic Regression )\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(train_vectors, y_train)\n",
    "\n",
    "# Calculating Accuracy\n",
    "clf.predict(test_vectors)\n",
    "print(\"Logistic Regression Accuracy Score -> \",clf.score(train_vectors,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of predicting the language of a given word is close to 90% for each algorithm. \n",
    "In this case I could say that,with only one feature the accuracy of a word classification is almost satisfying.\n",
    "The weak part of the algorithm is that we just used randomly selected words instead of Texts.\n",
    "If we are using texts instead of words which will give use opportunity to use more Natural Language Process techniques\n",
    "and therefore we will make better predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
